{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e79e74e",
   "metadata": {},
   "source": [
    "Import packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0358552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffba588",
   "metadata": {},
   "source": [
    "Check pandas version (to doublecheck if loaded):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59964838",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecce4c36",
   "metadata": {},
   "source": [
    "### Importing and inspecting data\n",
    "\n",
    "Import data from CSV: `inventory.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ba1838",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"inventory.csv\") # df is the typical abbreviation for dataframe! Careful with the working directory!\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c0d9a",
   "metadata": {},
   "source": [
    "Get basic information about dataset (info, shape, size):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9d5d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea06639",
   "metadata": {},
   "source": [
    "Summary statistics: describe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd55c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8b16ed",
   "metadata": {},
   "source": [
    "### Indexing & selection\n",
    "Columns can be called by simply selecting the column name from the dataframe, e.g. `df[\"name\"]`. Multiple columns can be listed! This can also be used to create new columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540075ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad66db6",
   "metadata": {},
   "source": [
    "Entries can be localized by their coordinates using `loc` (explicit indices) and `iloc` (implicit indices). Can be used to change single values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b5807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890e71f8",
   "metadata": {},
   "source": [
    "This can also be used for slicing! e.g. `df.iloc[startrow:endrow:interval, startcolumn:endcolumn:interval]` (endpoints not included! if one of the numbers not given: default = from start to end with interval 1, i.e. every entry)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5951ab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df.iloc[0:3:,::]\n",
    "df_small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f3f066",
   "metadata": {},
   "source": [
    "Columns are accessed using the `columns` attribute, rows using the `index` attribute (can be used for renaming the whole axis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c99e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small.columns = [\"A\", \"B\", \"C\", \"D\"]\n",
    "df_small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22dd3bb",
   "metadata": {},
   "source": [
    "Creating new columns, e.g. price per volume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2aa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"price_per_vol\"] = df[\"price\"]/df[\"bottle_volume\"] # equivalent to:\n",
    "# new_df = df.assign(price_per_vol = df[\"price\"]/df[\"bottle_volume\"]) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6f7d0c",
   "metadata": {},
   "source": [
    "Selecting with certain condition: Boolean masks for selecting entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Substance\"] == \"Ethanol\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62348f3",
   "metadata": {},
   "source": [
    "### Data cleaning & processing\n",
    "\n",
    "To delete rows and columns, `drop` can be used (specifying the axis!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259e1b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the last column on a copy of teh original df\n",
    "df_reduced = df.copy().drop(columns=[\"price_per_vol\"], axis=1)\n",
    "df_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed12926",
   "metadata": {},
   "source": [
    "Most important use cases: handle missing values and duplicates.\n",
    "\n",
    "Detect missing values: `isna()` - best used in combination with `sum()` or `any()`. Can be used on df or columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8550df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f7ad5a",
   "metadata": {},
   "source": [
    "If desired, rows with missing values can be dropped with `dropna()` (e.g. if crucial value). Good practice: Documentation! And keep original df as copy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7f760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy().dropna()\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea96952a",
   "metadata": {},
   "source": [
    "Duplicates can be detected by `duplicated()`. Duplicates can be dropped using `drop_duplicates()`. Good practice: Documentation and working on copies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aa7d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0997c5",
   "metadata": {},
   "source": [
    "Both cases, duplicates and missing values, can be treated with other options (see documentation)! Or completely different approaches may be valid, such as filling or flagging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34da9ca2",
   "metadata": {},
   "source": [
    "Types (info!) can be redefined using `astype`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b26981",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "df[\"bottle_volume\"] = df[\"bottle_volume\"].astype(float)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d139ce6",
   "metadata": {},
   "source": [
    "### Grouping & aggregation\n",
    "\n",
    "`groupby` is an important example of a split-apply-combine approach: first, entries in a specified column will be grouped together, then a function is applied (e.g. an aggregate such as mean, std.dev., sum) to all numerical values in each group, then the groups are recombined to give another dataframe.\n",
    "\n",
    "Single columns can be selected from the groups to which the aggregates will be applied. Use `agg()` to mix different aggregates for different columns (refer to documentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299194ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Substance\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb480747",
   "metadata": {},
   "source": [
    "### Merging and joining datasets\n",
    "\n",
    "`pd.merge` and `pd.concat` are very important functions to combine different Dataframes (or Series).\n",
    "\n",
    "First load as `df2` the CSV file `chemicals.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0bfc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"chemicals.csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ea6ced",
   "metadata": {},
   "source": [
    "`pd.concat` mainly appends the dataframes, per default as new rows (can be specified with axis!). `join=` defines if everything is kept (\"outer\") or only the entries that are existing in both (\"inner\"). `ignore_index=True` will replace the original indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab1aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_appended = pd.concat((df, df2), join=\"outer\", ignore_index=True)\n",
    "df_appended"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b4e05a",
   "metadata": {},
   "source": [
    "`pd.merge` fuses two dataframes together (specified with `left=` and `right=`) `on` a specified common key, `how` sets the merge type (similar as to the join type with `concat`, but with more options). Merges can be also done on different keys (`left_on=`, `right_on=`). `suffixes` can fix clashes when more columns bear the same name in the two dataframes (see documentaiton)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bfb635",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(left=df, right=df2, on=\"Substance\", how=\"outer\")\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b4429b",
   "metadata": {},
   "source": [
    "### Reshaping data\n",
    "\n",
    "`melt` transforms a \"wide table\" into a long one (\"Take many columns and stack them into rows.\"). Often this is done for visualisation. The basic syntax is: `pd.melt(df, id_vars=..., value_vars=..., var_name=..., value_name=...)`, where...\n",
    "\n",
    "...`id_vars`: columns to keep as identifiers (stay the same)\n",
    "...`value_vars`: columns that will be unpivoted (melted into rows)\n",
    "...`var_name`: name of the new column that will hold the former column names\n",
    "...`value_name`: name of the new column that will hold the values\n",
    "\n",
    "`pivot` is the reverse operation, `pivot_table` works in a similar way - refer to documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af28759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not the most meaningful example... (better one see dht_data)\n",
    "print(df)\n",
    "df_molten = df.melt(\n",
    "    id_vars=\"Substance\", \n",
    "    value_vars=[\"bottle_volume\", \"remaining_amount\", \"price\", \"price_per_vol\"],\n",
    "    var_name=\"container_property\",\n",
    "    value_name=\"value\"\n",
    "    )\n",
    "df_molten"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSA104",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
